{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1. Fill up the following information:\n",
    "    - **Your Name**:\n",
    "    - **Your email id**:\n",
    "    - **Your Batch**:\n",
    "    - **Your roll no**:\n",
    "2. This exam is 2 hours long.\n",
    "3. Full marks: 100\n",
    "4. Marking Scheme\n",
    "    - Section 1 [10 marks]: Answer all questions\n",
    "    - Section 2 [20 marks]: Answer any four (out of five questions)\n",
    "    - Section 3 [40 marks]: Answer any four (out of five questions)\n",
    "    - Section 4 [30 marks]: Answer any two (out of three questions)\n",
    "---\n",
    "1. This is an openbook exam.\n",
    "2. Fill up your answers in this notebook and submit.\n",
    "3. Change the filename to include your name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: True or False Type Questions\n",
    "\n",
    "## Questions\n",
    "\n",
    "1. Spark can execute any program where the data and the computation can be represented as a DAG.\n",
    "2. Spark can read data from SQL databases but not NoSQL databases.\n",
    "3. Spark RDDs are not fault-tolerant: if a node containing an RDD goes down, we have to restart all the calculations from scratch again.\n",
    "4. Transformations reduce RDDs to a number or a few numbers by aggregating them.\n",
    "5. If a datset is larger than the memory (RAM) allocated to a Spark cluster, then it cannot be processed by Spark.\n",
    "\n",
    "## Your Answer\n",
    "\n",
    "Write **True** or **False** as answer.\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Short Answer Type Questions\n",
    "\n",
    "## Questions\n",
    "\n",
    "Answer the following questions in one or two lines.\n",
    "\n",
    "1. What is an *anonymous function*?\n",
    "2. What does the lazy evaluation of RDDs mean in practice?\n",
    "3. What is the difference between *map()* and *flatMap()*?\n",
    "4. What are numeric RDD operations?\n",
    "5. What is a DataFrame? List 4 functions in Spark available for DataFrames.\n",
    "\n",
    "## Your Answer\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Long Answer Type Questions\n",
    "\n",
    "\n",
    "## Questions\n",
    "\n",
    "Answer the following questions in five to ten lines.\n",
    "\n",
    "1. What is an RDD? Explain the name.\n",
    "2. What is Feature Engineering? Why do we do it?\n",
    "3. Why do we need to encode categorical variables? Describe at least one scheme to encode categorical variables into numeric.\n",
    "4. Describe the pySpark workflow.\n",
    "    - How do we connect to Spark?\n",
    "    - How do we create Spark objects?\n",
    "    - How do we collect results from Spark?\n",
    "5. Describe how we can query Spark dataframes with an example of at least 2 operations.\n",
    "\n",
    "## Your Answer\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Hands-on Tasks\n",
    "\n",
    "## Questions\n",
    "\n",
    "Write the code to perform the following tasks:\n",
    "\n",
    "### Task 1\n",
    "\n",
    "1. Create a Python collection of 10,000 integers\n",
    "2. Create a Spark RDD from that collection\n",
    "3. Subtract one from each value using map\n",
    "4. Perform action collect to view results\n",
    "5. Perform action count to view counts\n",
    "6. Apply transformation filter (select only even numbers) and view results with collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Execute the following cell - it creates a file called *sample.txt* which we'll use in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 'Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu. In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo. Nullam dictum felis eu pede mollis pretium. Integer tincidunt. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim. Aliquam lorem ante, dapibus in, viverra quis, feugiat a, tellus. Phasellus viverra nulla ut metus varius laoreet. Quisque rutrum. Aenean imperdiet. Etiam ultricies nisi vel augue. Curabitur ullamcorper ultricies nisi. Nam eget dui. Etiam rhoncus. Maecenas tempus, tellus eget condimentum rhoncus, sem quam semper libero, sit amet adipiscing sem neque sed ipsum. Nam quam nunc, blandit vel, luctus pulvinar, hendrerit id, lorem. Maecenas nec odio et ante tincidunt tempus. Donec vitae sapien ut libero venenatis faucibus. Nullam quis ante. Etiam sit amet orci eget eros faucibus tincidunt. Duis leo. Sed fringilla mauris sit amet nibh. Donec sodales sagittis magna. Sed consequat, leo eget bibendum sodales, augue velit cursus nunc.' >> sample.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Directly import the text file *sample.txt* as a Spark RDD.\n",
    "2. Count the no of non-empty lines in the file.\n",
    "3. Count the no of characters in the file.\n",
    "4. Count the no of words of length greater than 3 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Here is a Python list containing a no of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = ['Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
    "       'Lorem Ipsum has been the industry\\'s standard dummy text ever since the 1500s,', \n",
    "       'when an unknown printer took a galley of type and scrambled it to make a type specimen book.',\n",
    "       'It has survived not only five centuries, ',\n",
    "       'but also the leap into electronic typesetting, ',\n",
    "       'remaining essentially unchanged.',\n",
    "       'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, ',\n",
    "       'and more recently with desktop publishing software like',\n",
    "       'Aldus PageMaker including versions of Lorem Ipsum.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Spark DataFrame which has one row per element in the list above (thus 9 rows for the 9 elements), and the following columns per row:\n",
    "\n",
    "1. The Text (the text is the corresponding element in the list above)\n",
    "    - For example, the first column of the first row has the following text: *Lorem Ipsum is simply dummy text of the printing and typesetting industry.*\n",
    "2. No of words in *The Text*\n",
    "3. No of characters in *The Text*\n",
    "4. No of punctuation marks in *The Text*\n",
    "5. No of stopwords in *The Text*.\n",
    "    - A word is considered a stopword if it belongs to the following list (capitalisation is to be ignored) : ['a', 'an', 'the', 'of', 'and', 'since', 'with']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
